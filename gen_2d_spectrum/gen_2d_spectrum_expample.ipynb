{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook: 2D Spectrum Processing\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Read complex data from files and assemble non-rephasing and rephasing signals.\n",
    "2. Perform a 2D Fast Fourier Transform (FFT) on these signals.\n",
    "3. Apply interpolation (both bilinear and then optional high-resolution interpolation).\n",
    "4. Normalize and visualize the resulting 2D spectrum.\n",
    "\n",
    "Make sure the file paths are correctly set before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.interpolate import griddata, RegularGridInterpolator\n",
    "from scipy.fft import fft2, fftshift, fftfreq\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Parameters and Initialize Arrays\n",
    "\n",
    "Here, we set:\n",
    "\n",
    "- The grid sizes (`size`, `size1`, `size2`), which might be relevant for the expected data dimensions.\n",
    "\n",
    "- Time-related parameters (`time`, `t_step`, `tau_step`, etc.).\n",
    "\n",
    "- File naming parameters.\n",
    "\n",
    "- Empty arrays to store the non-rephasing and rephasing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time parameters\n",
    "time = 1000\n",
    "t_size = 0      # size of detection time data at fixed coherent time.\n",
    "t_step = 10     # detection time step.\n",
    "tau_size = 0    # size of coherent time data at fixed detection time.\n",
    "tau_step = 10   # coherent time step.\n",
    "T = 0           # Population time.\n",
    "\n",
    "# Tau range\n",
    "tau_start = -600\n",
    "tau_end = 600\n",
    "\n",
    "# Grid sizes (modify as needed)\n",
    "size1 = 1000                                                # Storge space size of detection time data at fixed coherent time with pedding zeros.\n",
    "size2 = int((tau_end - tau_start) / tau_step / 2) + 1       # Storge space size of coherent time data at fixed detection time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Assemble Non-Rephasing Data\n",
    "\n",
    "We loop over the nagetive **tau** range for non-rephasing data:\n",
    "\n",
    "1. Select the file name based on chosen tau.\n",
    "\n",
    "2. Read each file as pairs of real and imaginary parts.\n",
    "\n",
    "3. Convert to complex values and store them in `non_rephaasing_data`.\n",
    "\n",
    "4. Update the dimensions of `t_size` and `tau_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-rephasing time windows\n",
    "non_rephaasing_tau_start = tau_start\n",
    "non_rephaasing_tau_end = 0\n",
    "\n",
    "# Arrays to store non-rephasing data\n",
    "non_rephaasing_data = np.zeros((size1, size2), dtype=np.complex128)\n",
    "\n",
    "for i, tau in enumerate(np.arange(non_rephaasing_tau_start, non_rephaasing_tau_end + 1, tau_step)):\n",
    "    filename = f\"../2d_output/out_{tau}_{T}.out\"\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        # Load file content as complex numbers\n",
    "        complex_numbers = np.loadtxt(filename, dtype=complex, \n",
    "                                     converters={0: lambda x: complex(float(x), 0), \n",
    "                                                 1: lambda x: complex(0, float(x))})\n",
    "        \n",
    "        # Combine real and imaginary parts into complex\n",
    "        d = np.array([complex(r.real, i.imag) for r, i in complex_numbers])\n",
    "        \n",
    "        # Multiply by 1j if needed (as per your original logic)\n",
    "        d = d * 1j\n",
    "        \n",
    "        # Fill non_rephaasing_data array\n",
    "        for j in range(size1):\n",
    "            if j < len(d):\n",
    "                non_rephaasing_data[j][i] = d[j]\n",
    "            else:\n",
    "                non_rephaasing_data[j][i] = 0\n",
    "\n",
    "    if i == 0:\n",
    "        t_size = len(d)\n",
    "    tau_size += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Assemble Rephasing Data\n",
    "\n",
    "Similar approach as for non-rephasing, but for the range from 0 to `tau_end`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rephaasing_data = np.zeros((size1, size2), dtype=np.complex128)\n",
    "rephasing_tau_start = 0\n",
    "rephasing_tau_end = tau_end\n",
    "\n",
    "for i, tau in enumerate(np.arange(rephasing_tau_start, rephasing_tau_end + 1, tau_step)):\n",
    "    filename = f\"../2d_output/out_{tau}_{T}.out\"\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        # Load file content as complex numbers\n",
    "        complex_numbers = np.loadtxt(filename, dtype=complex, \n",
    "                                     converters={0: lambda x: complex(float(x), 0), \n",
    "                                                 1: lambda x: complex(0, float(x))})\n",
    "        \n",
    "        # Combine real and imaginary parts\n",
    "        d = np.array([complex(r.real, i.imag) for r, i in complex_numbers])\n",
    "        \n",
    "        # Multiply by 1j if needed\n",
    "        d = d * 1j\n",
    "        \n",
    "        # Fill rephaasing_data array\n",
    "        for j in range(size1):\n",
    "            if j < len(d):\n",
    "                rephaasing_data[j][i] = d[j]\n",
    "            else:\n",
    "                rephaasing_data[j][i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform 2D FFT and Combine\n",
    "\n",
    "1. We compute the 2D Fourier transform of both non-rephasing and rephasing data.\n",
    "\n",
    "2. We use `fftshift` to center the zero-frequency component.\n",
    "\n",
    "3. We take the real part of the result.\n",
    "\n",
    "4. Combine them into a single `fft_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_non_rephaasing_data = fftshift(fft2(non_rephaasing_data)).real\n",
    "fft_rephaasing_data = fftshift(fft2(rephaasing_data)).real\n",
    "\n",
    "fft_data = fft_rephaasing_data + fft_non_rephaasing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (Optional) Apply Gaussian Filter\n",
    "\n",
    "If you want to smooth the data, you can use `gaussian_filter`. Adjust `sigma` values as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data = gaussian_filter(fft_data, sigma=(10, 0.6))  # Uncomment if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interpolate the FFT Data\n",
    "\n",
    "1. We set an interpolation factor (`interp_factor`).\n",
    "\n",
    "2. Create new grids along each axis.\n",
    "\n",
    "3. Use `RegularGridInterpolator` for bilinear interpolation.\n",
    "\n",
    "4. Update `fft_data` to the interpolated version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_factor = 2\n",
    "new_size1 = fft_data.shape[0] * interp_factor\n",
    "new_size2 = fft_data.shape[1] * interp_factor\n",
    "\n",
    "# Original grid\n",
    "x = np.arange(fft_data.shape[0])\n",
    "y = np.arange(fft_data.shape[1])\n",
    "\n",
    "# New grid for interpolation\n",
    "new_x = np.linspace(0, fft_data.shape[0] - 1, new_size1)\n",
    "new_y = np.linspace(0, fft_data.shape[1] - 1, new_size2)\n",
    "\n",
    "# Setup the interpolator\n",
    "interpolator = RegularGridInterpolator((x, y), fft_data)\n",
    "\n",
    "# Generate the new points (mesh)\n",
    "new_grid = np.meshgrid(new_x, new_y, indexing='ij')\n",
    "new_points = np.array([new_grid[0].ravel(), new_grid[1].ravel()]).T\n",
    "\n",
    "# Interpolate\n",
    "interpolated_data = interpolator(new_points).reshape(new_size1, new_size2)\n",
    "fft_data = interpolated_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prepare Frequency Axes\n",
    "\n",
    "We use `fftshift` and `fftfreq` to compute frequency arrays for `t` and `tau` axes. The factor `5308 * 2 * np.pi` seems to be a conversion to a specific unit (e.g., cm^{-1}).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, time + (new_size1 - t_size) * t_step, new_size1)\n",
    "tau = np.linspace(0, tau_end + (new_size2 - tau_size) * tau_step, new_size2)\n",
    "\n",
    "t = 5308 * 2 * np.pi * fftshift(fftfreq(len(t), t[1] - t[0]))\n",
    "tau = 5308 * 2 * np.pi * fftshift(fftfreq(len(tau), tau[1] - tau[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. High-Resolution Interpolation (Optional)\n",
    "\n",
    "We do a further interpolation onto an even finer grid (`high_res_factor`) using `scipy.interpolate.griddata` (cubic interpolation). This step is primarily for smooth contour plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res_factor = 8\n",
    "tau_high_res = np.linspace(tau.min(), tau.max(), size2 * high_res_factor)\n",
    "t_high_res = np.linspace(t.min(), t.max(), size1 * high_res_factor)\n",
    "X_high_res, Y_high_res = np.meshgrid(tau_high_res, t_high_res)\n",
    "\n",
    "X, Y = np.meshgrid(tau, t)\n",
    "points = np.array([X.flatten(), Y.flatten()]).T\n",
    "values = fft_data.flatten()\n",
    "\n",
    "fft_data_high_res = griddata(points, values, (X_high_res, Y_high_res), method='cubic')\n",
    "fft_data = fft_data_high_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Normalize and Plot\n",
    "\n",
    "1. Normalize the data by its absolute maximum (`fft_data / max_abs_value`).\n",
    "\n",
    "2. Create a contour plot and a color map (`imshow`).\n",
    "\n",
    "3. Optionally limit the plotted range in `xlim` and `ylim`.\n",
    "\n",
    "4. Uncomment lines to add colorbar, axis labels, ticks, etc., based on your preference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "max_abs_val = np.max(np.abs(fft_data))\n",
    "fft_data = fft_data / max_abs_val\n",
    "\n",
    "# Plot settings\n",
    "fontsize = 30\n",
    "labelpad = 12\n",
    "labelsize = 16\n",
    "\n",
    "plt.figure(figsize=(10, 8.5))\n",
    "\n",
    "# Contour levels\n",
    "lv = np.linspace(np.min(fft_data_high_res), np.max(fft_data_high_res), 12)\n",
    "norm = Normalize(vmin=-1.0, vmax=1.0)\n",
    "\n",
    "# Draw contour lines\n",
    "plt.contour(X_high_res, Y_high_res[::-1], fft_data_high_res, colors=['#000', '#000'], \n",
    "            levels=lv, norm=norm, linewidths=1)\n",
    "\n",
    "# Main image plot\n",
    "img = plt.imshow(\n",
    "    fft_data,\n",
    "    extent=(tau.min(), tau.max(), t.min(), t.max()),\n",
    "    cmap='jet',\n",
    "    norm=norm\n",
    ")\n",
    "\n",
    "# Optional colorbar\n",
    "plt.colorbar(img, ticks=[-1.0, -0.5, 0, 0.5, 1.0])\n",
    "\n",
    "# Axis labels\n",
    "plt.xlabel(r\"$\\omega_{\\tau} (cm^{-1})$\", fontsize=fontsize, labelpad=labelpad)\n",
    "plt.ylabel(r\"$\\omega_{t} (cm^{-1})$\", fontsize=fontsize, labelpad=labelpad)\n",
    "\n",
    "# Control ticks and range\n",
    "plt.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "plt.xlim(0, 900)\n",
    "plt.ylim(0, 900)\n",
    "\n",
    "# Optional title and saving\n",
    "# plt.title(f'Pulse width = 100 fs')\n",
    "# plt.savefig(f\"T{T}.eps\", format='eps', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Version Information\n",
    "\n",
    "Below we print out the versions of Python and the main libraries used in this notebook for reproducibility purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]\n",
      "NumPy version: 1.24.3\n",
      "SciPy version: 1.11.1\n",
      "Matplotlib version: 3.7.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"SciPy version:\", scipy.__version__)\n",
    "print(\"Matplotlib version:\", matplotlib.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
